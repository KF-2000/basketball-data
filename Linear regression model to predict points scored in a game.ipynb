{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.6 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "54bd7b183a5689457db50215dcf96c48b2aeef51ee043d07751f799ca7598ef2"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The names of each player I've collected data for and which seasons I've collected for each player in order.\n",
    "\n",
    "name = ['James Harden', 'Anthony Davis', 'LeBron James', 'Giannis Antetokounmpo', 'Kevin Durant', 'Russell Westbrook', 'Victor Oladipo', 'Paul George', 'Joel Embiid', 'Devin Booker', 'Bradley Beal', 'Trae Young', 'Luka Doncic']\n",
    "season = [['2018','2019','2020'],['2018','2020'],['2018'],['2018','2019','2020'],['2018','2019'],['2018'],['2018'],['2019'],['2019'],['2019'],['2019'],['2020'],['2020']]"
   ]
  },
  {
   "source": [
    "The below cell downloads the data I've collected from my files, and takes a split of the data before composing the training and testing data in order to get a reasonable distribution of data for different player's and their style of play in both the training and testing data.\n",
    "This is done to avoid overfitting of the training data, if for example most of the training data contains information from guards who tend to take and make more 3-point field goals compared to forwards or centers who take more 2-point field goals and free throws."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First I'm going to load all of the feature data into a single dataframe.\n",
    "\n",
    "feature_training = pd.DataFrame()\n",
    "feature_testing = pd.DataFrame()\n",
    "label_training = pd.DataFrame()\n",
    "label_testing = pd.DataFrame()\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(name)):\n",
    "    for j in range(len(season[i])):\n",
    "\n",
    "        # Downloading the file data from the appropriate file path.\n",
    "        # Loading a player's feature and label data for one season.\n",
    "\n",
    "        feature_data = pd.read_csv(r'C:\\Users\\frank\\OneDrive\\Documents\\DS\\ML Basketball Data\\Player Data\\{}\\{}'.format(name[i],season[i][j]),index_col=0)\n",
    "        label_data = pd.read_csv(r'C:\\Users\\frank\\OneDrive\\Documents\\DS\\ML Basketball Data\\Player Data\\{}\\Points\\{}'.format(name[i],season[i][j]),index_col=0)\n",
    "\n",
    "        # Splitting the data for each csv into train/test data\n",
    "\n",
    "        feature_train, feature_test, label_train, label_test = train_test_split(feature_data,label_data,test_size=0.2,random_state=5) # using the same random state will ensure the same indices are used for the train/test split on each set of data.\n",
    "\n",
    "        # After splitting the data I will load it into different train and test dataframes for both the features and label data.\n",
    "        \n",
    "        feature_training = pd.concat([feature_training,feature_train])\n",
    "        feature_testing = pd.concat([feature_testing,feature_test])\n",
    "        label_training = pd.concat([label_training,label_train])\n",
    "        label_testing = pd.concat([label_testing,label_test])\n",
    "\n",
    "feature_training.reset_index(drop='True', inplace=True)\n",
    "label_training.reset_index(drop='True', inplace=True)\n",
    "feature_testing.reset_index(drop='True', inplace=True)\n",
    "label_testing.reset_index(drop='True', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Finding and removing NaN values from the datasets\n",
    "\n",
    "print(feature_training.isnull().values.any())\n",
    "print(label_training.isnull().values.any())\n",
    "print(feature_testing.isnull().values.any())\n",
    "print(label_testing.isnull().values.any())\n",
    "\n",
    "null_f = [] # list to contain the indices of rows with nan values in the feature training data\n",
    "for i in range(len(feature_training)):\n",
    "    if str(feature_training.iloc[i].isnull().values.any()) == 'True':\n",
    "        null_f.append(i)\n",
    "\n",
    "null_l = [] # list to contain the indices of rows with nan values in the label training data\n",
    "for i in range(len(label_training)):\n",
    "    if str(label_training.iloc[i].isnull().values.any()) == 'True':\n",
    "        null_l.append(i)\n",
    "\n",
    "feature_training = feature_training.drop(null_f,axis=0)\n",
    "label_training = label_training.drop(null_l,axis=0)\n",
    "\n",
    "print(feature_training.isnull().values.any())\n",
    "print(label_training.isnull().values.any())\n",
    "print(feature_testing.isnull().values.any())\n",
    "print(label_testing.isnull().values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "MSE: -4.8901894369184547e-29\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Creating the ordinary least squares model and generating predictions from this.\n",
    "\n",
    "stratkf = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "scaler = StandardScaler()\n",
    "model = LinearRegression()\n",
    "\n",
    "# Creating a pipeline so that data is normalised before predictions\n",
    "estimators = []\n",
    "estimators.append(('normalise', scaler))\n",
    "estimators.append(('linear model', model))\n",
    "pipeline  = Pipeline(estimators)\n",
    "\n",
    "# Training and making predictions from the model\n",
    "\n",
    "mean_squared_errors = cross_val_score(pipeline, feature_training, label_training, cv=stratkf, scoring='neg_mean_squared_error')\n",
    "predictions = cross_val_predict(pipeline, feature_testing, label_testing).flatten() # generating predictions\n",
    "accuracy = accuracy_score(np.round(np.array(label_testing)).flatten(), np.round(predictions))\n",
    "mse = np.mean(mean_squared_errors) # average MSE from each split of the data\n",
    "print('MSE:', mse)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "source": [
    "Already from this we have a 100% accurate model with almost no mean squared error (because predicted values are rounded). The model might be more efficient if we use less features, and only consider features actually contributing to the points scored by a player; specifically FG, 3P, and FT."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "MSE: -2.2712133847180432e-29\nAccuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Only selecting the most significant features for our model.\n",
    "\n",
    "features = ['FG','3P','FT']\n",
    "feature_training = feature_training[features]\n",
    "feature_testing = feature_testing[features]\n",
    "\n",
    "stratkf = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "model = LinearRegression()\n",
    "mean_squared_errors = cross_val_score(model, feature_training, label_training, cv=stratkf, scoring='neg_mean_squared_error')\n",
    "predictions = cross_val_predict(model, feature_testing, label_testing).flatten() # generating predictions\n",
    "accuracy = accuracy_score(np.round(np.array(label_testing)).flatten(), np.round(predictions))\n",
    "mse = np.mean(mean_squared_errors) # average MSE from each split of the data\n",
    "print('MSE:', mse)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ]
}