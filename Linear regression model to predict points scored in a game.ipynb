{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.6 64-bit ('base': conda)",
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "54bd7b183a5689457db50215dcf96c48b2aeef51ee043d07751f799ca7598ef2"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The names of each player I've collected data for and which seasons I've collected for each player in order.\n",
    "\n",
    "name = ['James Harden', 'Anthony Davis', 'LeBron James', 'Giannis Antetokounmpo', 'Kevin Durant', 'Russell Westbrook', 'Victor Oladipo', 'Paul George', 'Joel Embiid', 'Devin Booker', 'Bradley Beal', 'Trae Young', 'Luka Doncic']\n",
    "season = [['2018','2019','2020'],['2018','2020'],['2018'],['2018','2019','2020'],['2018','2019'],['2018'],['2018'],['2019'],['2019'],['2019'],['2019'],['2020'],['2020']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First I'm going to load all of the feature data into a single dataframe.\n",
    "\n",
    "feature_training = pd.DataFrame()\n",
    "feature_testing = pd.DataFrame()\n",
    "label_training = pd.DataFrame()\n",
    "label_testing = pd.DataFrame()\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(name)):\n",
    "    for j in range(len(season[i])):\n",
    "\n",
    "        # Downloading the file data from the appropriate file path.\n",
    "        # Loading a player's feature and label data for one season.\n",
    "\n",
    "        feature_data = pd.read_csv(r'C:\\Users\\frank\\OneDrive\\Documents\\DS\\ML Basketball Data\\Player Data\\{}\\{}'.format(name[i],season[i][j]),index_col=0)\n",
    "        label_data = pd.read_csv(r'C:\\Users\\frank\\OneDrive\\Documents\\DS\\ML Basketball Data\\Player Data\\{}\\Points\\{}'.format(name[i],season[i][j]),index_col=0)\n",
    "\n",
    "        # Splitting the data for each csv into train/test data\n",
    "\n",
    "        feature_train, feature_test, label_train, label_test = train_test_split(feature_data,label_data,test_size=0.2,random_state=5) # using the same random state will ensure the same indices are used for the train/test split on each set of data.\n",
    "\n",
    "        # After splitting the data I will load it into different train and test dataframes for both the features and label data.\n",
    "        \n",
    "        feature_training = pd.concat([feature_training,feature_train])\n",
    "        feature_testing = pd.concat([feature_testing,feature_test])\n",
    "        label_training = pd.concat([label_training,label_train])\n",
    "        label_testing = pd.concat([label_testing,label_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Scaling the data before using it to fit the model.\n",
    "# It's important to fit the scaler only to a single data set (feature training, feature testing etc.) as this will exclude information from the test sets.\n",
    "\n",
    "scaler = StandardScaler()\n",
    "f_train_scaled = pd.DataFrame(scaler.fit_transform(feature_training),columns=feature_training.columns.values.tolist())\n",
    "f_test_scaled = pd.DataFrame(scaler.fit_transform(feature_testing),columns=feature_testing.columns.values.tolist())\n",
    "l_train_scaled = pd.DataFrame(scaler.fit_transform(label_training),columns=label_training.columns.values.tolist())\n",
    "l_test_scaled = pd.DataFrame(scaler.fit_transform(label_testing),columns=label_testing.columns.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     Actual Points  Predicted Points  Difference\n",
       "0             25.0         24.951432    0.048568\n",
       "1             48.0         48.855793   -0.855793\n",
       "2             24.0         23.706731    0.293269\n",
       "3             56.0         57.252383   -1.252383\n",
       "4             41.0         41.266647   -0.266647\n",
       "..             ...               ...         ...\n",
       "274           42.0         42.368958   -0.368958\n",
       "275           35.0         35.242513   -0.242513\n",
       "276           29.0         29.081077   -0.081077\n",
       "277           27.0         27.161144   -0.161144\n",
       "278           38.0         38.579978   -0.579978\n",
       "\n",
       "[279 rows x 3 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Actual Points</th>\n      <th>Predicted Points</th>\n      <th>Difference</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>25.0</td>\n      <td>24.951432</td>\n      <td>0.048568</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>48.0</td>\n      <td>48.855793</td>\n      <td>-0.855793</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>24.0</td>\n      <td>23.706731</td>\n      <td>0.293269</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>56.0</td>\n      <td>57.252383</td>\n      <td>-1.252383</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>41.0</td>\n      <td>41.266647</td>\n      <td>-0.266647</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>274</th>\n      <td>42.0</td>\n      <td>42.368958</td>\n      <td>-0.368958</td>\n    </tr>\n    <tr>\n      <th>275</th>\n      <td>35.0</td>\n      <td>35.242513</td>\n      <td>-0.242513</td>\n    </tr>\n    <tr>\n      <th>276</th>\n      <td>29.0</td>\n      <td>29.081077</td>\n      <td>-0.081077</td>\n    </tr>\n    <tr>\n      <th>277</th>\n      <td>27.0</td>\n      <td>27.161144</td>\n      <td>-0.161144</td>\n    </tr>\n    <tr>\n      <th>278</th>\n      <td>38.0</td>\n      <td>38.579978</td>\n      <td>-0.579978</td>\n    </tr>\n  </tbody>\n</table>\n<p>279 rows × 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# Creating the ordinary least squares model and generating predictions from this.\n",
    "\n",
    "model = sm.OLS(l_train_scaled,f_train_scaled,missing='drop').fit()\n",
    "predictions = model.predict(f_test_scaled)\n",
    "preds = scaler.inverse_transform(predictions)\n",
    "comparison = pd.DataFrame()\n",
    "comparison['Actual Points'] = np.array(label_testing).flatten()\n",
    "comparison['Predicted Points'] = np.array(preds)\n",
    "comparison['Difference'] = comparison['Actual Points'] - comparison['Predicted Points']\n",
    "comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 OLS Regression Results                                \n",
       "=======================================================================================\n",
       "Dep. Variable:                    PTS   R-squared (uncentered):                   1.000\n",
       "Model:                            OLS   Adj. R-squared (uncentered):              1.000\n",
       "Method:                 Least Squares   F-statistic:                          1.642e+32\n",
       "Date:                Sat, 17 Oct 2020   Prob (F-statistic):                        0.00\n",
       "Time:                        20:05:21   Log-Likelihood:                          35781.\n",
       "No. Observations:                1077   AIC:                                 -7.155e+04\n",
       "Df Residuals:                    1069   BIC:                                 -7.151e+04\n",
       "Df Model:                           8                                                  \n",
       "Covariance Type:            nonrobust                                                  \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "FG             0.7183   6.76e-17   1.06e+16      0.000       0.718       0.718\n",
       "FGA         4.684e-17   6.62e-17      0.707      0.480   -8.31e-17    1.77e-16\n",
       "3P             0.2190   5.56e-17   3.94e+15      0.000       0.219       0.219\n",
       "3PA         7.685e-16   6.16e-17     12.467      0.000    6.48e-16    8.89e-16\n",
       "FT             0.4472   9.61e-17   4.65e+15      0.000       0.447       0.447\n",
       "FTA         2.914e-16   9.18e-17      3.176      0.002    1.11e-16    4.72e-16\n",
       "USG%        1.735e-17   4.38e-17      0.396      0.692   -6.85e-17    1.03e-16\n",
       "ORtg       -1.284e-16   4.95e-17     -2.592      0.010   -2.26e-16   -3.12e-17\n",
       "==============================================================================\n",
       "Omnibus:                       55.102   Durbin-Watson:                   0.841\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               62.328\n",
       "Skew:                          -0.579   Prob(JB):                     2.92e-14\n",
       "Kurtosis:                       3.220   Cond. No.                         9.08\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ],
      "text/html": "<table class=\"simpletable\">\n<caption>OLS Regression Results</caption>\n<tr>\n  <th>Dep. Variable:</th>           <td>PTS</td>       <th>  R-squared (uncentered):</th>       <td>   1.000</td> \n</tr>\n<tr>\n  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th>  <td>   1.000</td> \n</tr>\n<tr>\n  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>           <td>1.642e+32</td>\n</tr>\n<tr>\n  <th>Date:</th>             <td>Sat, 17 Oct 2020</td> <th>  Prob (F-statistic):</th>            <td>  0.00</td>  \n</tr>\n<tr>\n  <th>Time:</th>                 <td>20:05:21</td>     <th>  Log-Likelihood:    </th>           <td>  35781.</td> \n</tr>\n<tr>\n  <th>No. Observations:</th>      <td>  1077</td>      <th>  AIC:               </th>          <td>-7.155e+04</td>\n</tr>\n<tr>\n  <th>Df Residuals:</th>          <td>  1069</td>      <th>  BIC:               </th>          <td>-7.151e+04</td>\n</tr>\n<tr>\n  <th>Df Model:</th>              <td>     8</td>      <th>                     </th>               <td> </td>    \n</tr>\n<tr>\n  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>               <td> </td>    \n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n    <td></td>      <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n</tr>\n<tr>\n  <th>FG</th>   <td>    0.7183</td> <td> 6.76e-17</td> <td> 1.06e+16</td> <td> 0.000</td> <td>    0.718</td> <td>    0.718</td>\n</tr>\n<tr>\n  <th>FGA</th>  <td> 4.684e-17</td> <td> 6.62e-17</td> <td>    0.707</td> <td> 0.480</td> <td>-8.31e-17</td> <td> 1.77e-16</td>\n</tr>\n<tr>\n  <th>3P</th>   <td>    0.2190</td> <td> 5.56e-17</td> <td> 3.94e+15</td> <td> 0.000</td> <td>    0.219</td> <td>    0.219</td>\n</tr>\n<tr>\n  <th>3PA</th>  <td> 7.685e-16</td> <td> 6.16e-17</td> <td>   12.467</td> <td> 0.000</td> <td> 6.48e-16</td> <td> 8.89e-16</td>\n</tr>\n<tr>\n  <th>FT</th>   <td>    0.4472</td> <td> 9.61e-17</td> <td> 4.65e+15</td> <td> 0.000</td> <td>    0.447</td> <td>    0.447</td>\n</tr>\n<tr>\n  <th>FTA</th>  <td> 2.914e-16</td> <td> 9.18e-17</td> <td>    3.176</td> <td> 0.002</td> <td> 1.11e-16</td> <td> 4.72e-16</td>\n</tr>\n<tr>\n  <th>USG%</th> <td> 1.735e-17</td> <td> 4.38e-17</td> <td>    0.396</td> <td> 0.692</td> <td>-6.85e-17</td> <td> 1.03e-16</td>\n</tr>\n<tr>\n  <th>ORtg</th> <td>-1.284e-16</td> <td> 4.95e-17</td> <td>   -2.592</td> <td> 0.010</td> <td>-2.26e-16</td> <td>-3.12e-17</td>\n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n  <th>Omnibus:</th>       <td>55.102</td> <th>  Durbin-Watson:     </th> <td>   0.841</td>\n</tr>\n<tr>\n  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  62.328</td>\n</tr>\n<tr>\n  <th>Skew:</th>          <td>-0.579</td> <th>  Prob(JB):          </th> <td>2.92e-14</td>\n</tr>\n<tr>\n  <th>Kurtosis:</th>      <td> 3.220</td> <th>  Cond. No.          </th> <td>    9.08</td>\n</tr>\n</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "source": [
    "From the above summary of the model, we can see that the the FGA, 3PA, FTA, USG%, and ORtg statistics have very little effect on the regression model."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     Actual Points  Predicted Points  Difference\n",
       "0             25.0         24.951432    0.048568\n",
       "1             48.0         48.855793   -0.855793\n",
       "2             24.0         23.706731    0.293269\n",
       "3             56.0         57.252383   -1.252383\n",
       "4             41.0         41.266647   -0.266647\n",
       "..             ...               ...         ...\n",
       "274           42.0         42.368958   -0.368958\n",
       "275           35.0         35.242513   -0.242513\n",
       "276           29.0         29.081077   -0.081077\n",
       "277           27.0         27.161144   -0.161144\n",
       "278           38.0         38.579978   -0.579978\n",
       "\n",
       "[279 rows x 3 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Actual Points</th>\n      <th>Predicted Points</th>\n      <th>Difference</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>25.0</td>\n      <td>24.951432</td>\n      <td>0.048568</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>48.0</td>\n      <td>48.855793</td>\n      <td>-0.855793</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>24.0</td>\n      <td>23.706731</td>\n      <td>0.293269</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>56.0</td>\n      <td>57.252383</td>\n      <td>-1.252383</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>41.0</td>\n      <td>41.266647</td>\n      <td>-0.266647</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>274</th>\n      <td>42.0</td>\n      <td>42.368958</td>\n      <td>-0.368958</td>\n    </tr>\n    <tr>\n      <th>275</th>\n      <td>35.0</td>\n      <td>35.242513</td>\n      <td>-0.242513</td>\n    </tr>\n    <tr>\n      <th>276</th>\n      <td>29.0</td>\n      <td>29.081077</td>\n      <td>-0.081077</td>\n    </tr>\n    <tr>\n      <th>277</th>\n      <td>27.0</td>\n      <td>27.161144</td>\n      <td>-0.161144</td>\n    </tr>\n    <tr>\n      <th>278</th>\n      <td>38.0</td>\n      <td>38.579978</td>\n      <td>-0.579978</td>\n    </tr>\n  </tbody>\n</table>\n<p>279 rows × 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "# Only selecting the most significant features for our model.\n",
    "\n",
    "features = ['FG','3P','FT']\n",
    "feature_training = feature_training[features]\n",
    "feature_testing = feature_testing[features]\n",
    "\n",
    "# Scaling the data once again.\n",
    "\n",
    "f_train_scaled = pd.DataFrame(scaler.fit_transform(feature_training),columns=feature_training.columns.values.tolist())\n",
    "f_test_scaled = pd.DataFrame(scaler.fit_transform(feature_testing),columns=feature_testing.columns.values.tolist())\n",
    "l_train_scaled = pd.DataFrame(scaler.fit_transform(label_training),columns=label_training.columns.values.tolist())\n",
    "l_test_scaled = pd.DataFrame(scaler.fit_transform(label_testing),columns=label_testing.columns.values.tolist())\n",
    "\n",
    "model = sm.OLS(l_train_scaled,f_train_scaled,missing='drop').fit()\n",
    "predictions = model.predict(f_test_scaled)\n",
    "preds = scaler.inverse_transform(predictions)\n",
    "comparison = pd.DataFrame()\n",
    "comparison['Actual Points'] = np.array(label_testing).flatten()\n",
    "comparison['Predicted Points'] = np.array(preds)\n",
    "comparison['Difference'] = comparison['Actual Points'] - comparison['Predicted Points']\n",
    "comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 OLS Regression Results                                \n",
       "=======================================================================================\n",
       "Dep. Variable:                    PTS   R-squared (uncentered):                   1.000\n",
       "Model:                            OLS   Adj. R-squared (uncentered):              1.000\n",
       "Method:                 Least Squares   F-statistic:                          1.336e+33\n",
       "Date:                Sat, 17 Oct 2020   Prob (F-statistic):                        0.00\n",
       "Time:                        20:06:48   Log-Likelihood:                          36379.\n",
       "No. Observations:                1077   AIC:                                 -7.275e+04\n",
       "Df Residuals:                    1074   BIC:                                 -7.274e+04\n",
       "Df Model:                           3                                                  \n",
       "Covariance Type:            nonrobust                                                  \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "FG             0.7183   1.69e-17   4.25e+16      0.000       0.718       0.718\n",
       "3P             0.2190   1.69e-17    1.3e+16      0.000       0.219       0.219\n",
       "FT             0.4472   1.61e-17   2.78e+16      0.000       0.447       0.447\n",
       "==============================================================================\n",
       "Omnibus:                      181.769   Durbin-Watson:                   1.281\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              329.119\n",
       "Skew:                           1.031   Prob(JB):                     3.41e-72\n",
       "Kurtosis:                       4.757   Cond. No.                         1.48\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ],
      "text/html": "<table class=\"simpletable\">\n<caption>OLS Regression Results</caption>\n<tr>\n  <th>Dep. Variable:</th>           <td>PTS</td>       <th>  R-squared (uncentered):</th>       <td>   1.000</td> \n</tr>\n<tr>\n  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th>  <td>   1.000</td> \n</tr>\n<tr>\n  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>           <td>1.336e+33</td>\n</tr>\n<tr>\n  <th>Date:</th>             <td>Sat, 17 Oct 2020</td> <th>  Prob (F-statistic):</th>            <td>  0.00</td>  \n</tr>\n<tr>\n  <th>Time:</th>                 <td>20:06:48</td>     <th>  Log-Likelihood:    </th>           <td>  36379.</td> \n</tr>\n<tr>\n  <th>No. Observations:</th>      <td>  1077</td>      <th>  AIC:               </th>          <td>-7.275e+04</td>\n</tr>\n<tr>\n  <th>Df Residuals:</th>          <td>  1074</td>      <th>  BIC:               </th>          <td>-7.274e+04</td>\n</tr>\n<tr>\n  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>               <td> </td>    \n</tr>\n<tr>\n  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>               <td> </td>    \n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n   <td></td>     <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n</tr>\n<tr>\n  <th>FG</th> <td>    0.7183</td> <td> 1.69e-17</td> <td> 4.25e+16</td> <td> 0.000</td> <td>    0.718</td> <td>    0.718</td>\n</tr>\n<tr>\n  <th>3P</th> <td>    0.2190</td> <td> 1.69e-17</td> <td>  1.3e+16</td> <td> 0.000</td> <td>    0.219</td> <td>    0.219</td>\n</tr>\n<tr>\n  <th>FT</th> <td>    0.4472</td> <td> 1.61e-17</td> <td> 2.78e+16</td> <td> 0.000</td> <td>    0.447</td> <td>    0.447</td>\n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n  <th>Omnibus:</th>       <td>181.769</td> <th>  Durbin-Watson:     </th> <td>   1.281</td>\n</tr>\n<tr>\n  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 329.119</td>\n</tr>\n<tr>\n  <th>Skew:</th>          <td> 1.031</td>  <th>  Prob(JB):          </th> <td>3.41e-72</td>\n</tr>\n<tr>\n  <th>Kurtosis:</th>      <td> 4.757</td>  <th>  Cond. No.          </th> <td>    1.48</td>\n</tr>\n</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ]
}